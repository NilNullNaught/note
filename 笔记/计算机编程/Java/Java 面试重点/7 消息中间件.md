<div STYLE="page-break-after: always;">
	<br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
	<center><h3><font size="20px">
        文件名
    </font></h3></center>
	<br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
</div>

# 1	消息中间件概述

## 1.1	消息中间件简介

##### 什么是消息中间件

消息中间件也称为消息队列（Message Queue），消息队列是应用程序和应用程序之间的通信方法。

<br>

##### 为什么需要消息中间件

在项目中，可以通过消息中间件将一些无需即时返回且耗时的操作提取出来，进行 **异步处理**，而这种异步处理的方式大大的节省了服务器的请求响应时间，从而 **提高了系统的吞吐量**。

<br>

##### 消息队列的实际应用场景

1. **任务异步处理**：将不需要同步处理且耗时长的操作，交由消息队列通知消息接收方，进行异步处理。提高了应用程序的响应时间。
2. **应用程序解耦合**：MQ 相当于一个中介，生产方通过 MQ 与消费方交互，它将应用程序进行解耦合。
3. **削峰填谷**：在高并发大流量场景下，请求接收速度超过服务器的处理速度。这时可以通过消息中间件保存请求，保证系统在不被冲溃的前提下，请求不至于丢失（当然，这可能会造成部分请求的响应过慢甚至超时）。

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>
## 1.2	消息队列的底层实现方式

##### AMQP 和 JMS 是什么？

简单的说，AMQP 和 JMS 是实现消息队列的两种主流方式。

<br>

##### AMQP 简介

AMQP 是一种协议，更准确的说是一种 binary wire-level protocol（链接协议）。这是其和 JMS 的本质差别，AMQP 不从 API 层进行限定，而是直接定义网络交换的数据格式。

<br>

##### JMS

JMS 即 Java 消息服务（JavaMessage Service）应用程序接口，是一个 Java 平台中关于面向消息中间件（MOM）的 API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。

<br>

##### AMQP 与 JMS 区别

1. JMS 是定义了统一的接口，来对消息操作进行统一；AMQP 是通过规定协议来统一数据交互的格式;
2. JMS 限定了必须使用 Java 语言；AMQP只是协议，不规定实现方式，因此是跨语言的;
3. JMS 规定了两种消息模式；而 AMQP 的消息模式更加丰富.

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 1.3	四种常用的消息中间件

##### RabbitMQ

 RabbitMQ 是一个由 **Erlang语言开发** 的基于 AMQP 标准的 **开源框架**。RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在 **易用性、扩展性、高可用性等方面表现不俗**。

###### 主要特性

1. **高可靠性、 高可用性**；
2. **灵活的路由**；
3. **支持消息集群**；
4. 支持 **多种协议**（除支持AMQP协议之外，还可以通过插件的方式支持其他消息队列协议，如 STOMP、MQTT)
5. 支持多语言客户端
6. **提供跟踪机制**
7. 提供管理界面
8. 提供插件机制 （RabbitMQ提供了许多插件，也可以编写自己的插件）

###### 优点与缺点

RabbitMQ 最大的优势在于提供了比较灵活的消息 **路由策略、高可用性、可靠性以及丰富的插件、多种平台支持** 和完善的文档。不过，由于 AMQP 协议本身导致它的实现比较重量，从而使得与其他 MQ (比如Kafka) 对比其吞吐量处于下风。

<br>

##### ActiveMQ

ActiveMQ 是 **由Apache出品的一款开源消息中间件**，旨在为应用程序 **提供高效、可扩展、稳定、安全的企业级消息通信**。ActiveMQ 实现了 JMS 1.1 并提供了很多附加的特性，比如 JMX 管理、**主从管理、消息组通信、消息优先级、延迟接收消息、虚拟接收者、消息持久化、消息队列监控等**。

###### 主要特性

1. **支持**Java、C、C++、C#、Ruby、Perl、Python、PHP等**多种语言的客户端和协议**，如 OpenWire、STOMP、AMQP、MQTT 协议。
2. **提供了**像消**息组通信、消息优先级、延迟接收消息、虚拟接收者、消息持久化**之类的**高级特性**。
3. 完全支持JMS 1.1 和 J2EE 1.4 规范 (包括持久化、分布式事务消息、事务)
4. 支持Spring框架，ActiveMQ 可以通过Spring 的配置文件方式很容易嵌入Spring应用中。
5. 通过了常见的 J2EE 服务器测试，比如 TomEE、Geronimo、JBoss、GlassFish、WebLogic。
6. 连接方式多样化，ActiveMQ 提供了**多种连接方式**，例如 in-VM、TCP、SSL、NIO、UDP、多播、JGroups、JXTA。
7. 支持通过使用JDBC 和 Journal 实现消息的快速持久化。
8. 为高性能集群、客户端-服务器、点对点通信等场景而设计。
9. 提供了技术和语言中立的REST API 接口。
10. 支持以 AJAX 方式调用 ActiveMQ。
11. 可以作为内存中的 JMS 提供者，非常适合 JMS 单元测试。

<br>

##### Kafka

Kafka 最早是由 LinkedIn 公司开发的一**种分布式的** 基于 **发布/订阅 的消息系**统，后来成为 **Apache 的顶级项目**。

###### 主要特性

1. 同时为发布和订阅提**供高吞吐量**。 (Kafka 的设计目标是以时间复杂度为 O(1) 的方式提供消息持久化能力的，即使对TB级别以上数据也能保证常数时间的访问性能，即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条消息的传输)
2. **消息持久化。** (将消息持久化到磁盘，因此可用于批量消费，例如 ETL 以及实时应用程序。通过将数据持久化到硬盘以及复制可以防止数据丢失。)
3. **分布式。**   (支持服务器间的消息分区及分布式消费，同时保证每个Partition 内的消息顺序传输。其内部的Producer、Broker 和 Consumer 都是分布式架构，这更易于向外扩展。)
4. **消费消息采用 Pull 模式**。(消息被处理的状态是在 Consumer 端维护的，而不是由服务器端维护，Broker 无状态，Consumer 自己保存offet。)
5. **支持Online 和 Offline 场景**，同时支持离线数据处理和实时数据处理。

<br>

##### RocketMQ

RocketMQ 是 **阿里巴巴于2012年开源的** 分布式消息中间件，后来捐赠给 Apache软件基金会，并于2017年9月25日成为Apache的顶级项目。作为经历过多次阿里巴巴“双11” 这种“超级工程”的洗礼并有稳定出色表现的国产中间件，以其**高性能、低延迟和高可靠等**特性近年来被越来越多的国内企业所使用。

###### 主要特性

1. **具有灵活的可扩展性**：RocketMQ 天然支持集群，其核心四大组件（NameServer、Broker、Producer、Consumer）的每一个都可以在没有单点故障的情况下进行水平扩展。
2. **具有海量消息堆积能力**。 （RocketMQ 采用零拷贝原理实现了超大量消息的堆积能力，据说单机已经可以支持亿级消息堆积，而且在堆积了这么多消息后依然保持写入低延迟。
3. **支持顺序消息**：RocketMQ 可以保证消息消费者按照消息发送的顺序对消息进行消费。顺序消息分为全局有序消息和局部有序消息，一般推荐使用局部有序消息，即生产者通过将某一类消息按顺序发送至同一个队列中来实现。
4. **支持多种消息过滤方式**：消息过滤分为在服务器端过滤和在消费端过滤。在服务器端过滤时可以按照消息消费者的要求进行过滤，优点是减少了不必要的消息传输，缺点是增加了消息服务器的负担，实现相对复杂。消费端过滤则完全由具体应用自定义实现，这种方式更加灵活，缺点是很多无用的消息会被传输给消息消费者。
5. **支持事务消息**：RocketMQ 除支持普通消息、顺序消息之外，还支持事务消息，这个特性对于分布式事务来说提供了另一种解决思路。
6. **支持回溯消费**：回溯消费是指对于消费者已经消费成功的消息，由于业务需求需要重新消费。RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

# 2	RabbitMQ

## 2.1	RabbitMQ 的架构设计

##### RabbitMQ 采用的通讯协议

RabbitMQ 底层采用 AMQP 实现。在 mq 领域中，producer 将 msg 发送到 queue，然后 consumer 通过消费 queue，完成 producer 和 consumer 之间的解耦。

rabbitmq 是由 Exchange 决定 msg 应该怎么样发送到目标 queue

<br>

##### 核心概念

1. **Broker**：它提供一种传输服务，它的角色就是维护一条从生产者到消费者的路线，保证数据能按照指定的方式进行传输
2. **Exchange**：消息交换机,它指定消息按什么规则,路由到哪个队列。 
3. **Queue**：消息的载体,每个消息都会被投到一个或多个队列。 
4. **Binding**：绑定，它的作用就是把 exchange 和 queue 按照路由规则绑定起来.
5. **Routing Key**：路由关键字，exchange 根据这个关键字进行消息投递。 
6. **vhost**：虚拟主机,一个 broker 里可以有多个 vhost，用作不同用户的权限分离。
7. **Producer**：消息生产者,就是投递消息的程序. 
8. **Consumer**：消息消费者,就是接受消息的程序. 
9. **Channel**：消息通道,在客户端的每个连接里,可建立多个channel

<br>

##### RabbitMQ 的Exchange

1. **Direct Exchange**：直接匹配，通过 Exchange 名称 + RountingKey 来发送与接收消息；
2. **Fanout Exchange**：广播订阅,向所有的消费者发布消息,但是只有消费者将队列绑定到该路由器才能收到消息，忽略Routing Key；
3. **Topic Exchange**：主题匹配订阅,这里的主题指的是 RoutingKey，RoutingKey 可以采用通配符，如：\* 或 \#，RoutingKey 命名采用 \. 来分隔多个词，只有消息这将队列绑定到该路由器且指定RoutingKey符合匹配规则时才能收到消息；
4. **Headers Exchange**：消息头订阅，消息发布前，为消息定义一个或多个键值对的消息头，然后消费者接收消息同时需要定义类似的键值对请求头：(如：x-mactch=all 或者 x_match=any)，只有请求头与消息头匹配，才能接收消息，忽略 RoutingKey；
5. **默认的exchange**：如果用空字符串去声明一个exchange，那么系统就会使用”amq.direct”这个exchange，我们创建一个 queue 时，默认的都会有一个和新建 queue 同名的 routingKey 绑定到这个默认的 exchange 上去。

<br>

----

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>
## 2.2	RabbitMQ 如何确保消息发送和消息接收

##### 消息发送确认

###### ConfirmCallback方法

ConfirmCallback 是一个回调接口，消息发送到 Broker 后触发回调，确认消息是否到达 Broker 服务器，**也就是只确认是否正确到达 Exchange 中。**

###### ReturnCallback方法

通过实现 ReturnCallback 接口，启动消息失败返回，此接口是在交换器路由不到队列时触发回调，该方法可以不使用，因为交换器和队列是在代码里绑定的，如果消息成功投递到 Broker 后几乎不存在绑定队列失败，除非你代码写错了。

<br>

##### 消息接收确认

RabbitMQ 消息确认机制（ACK）默认是自动确认的，自动确认会在消息发送给消费者后立即确认，但存在丢失消息的可能，如果消费端消费逻辑抛出异常，假如你用回滚了也只是保证了数据的一致性，但是消息还是丢了，也就是消费端没有处理成功这条消息，那么就相当于丢失了消息。

###### 消息确认的三种模式

1. AcknowledgeMode.NONE：自动确认。
2. AcknowledgeMode.AUTO：根据情况确认。
3. AcknowledgeMode.MANUAL：手动确认。消费者收到消息后，手动调用 Basic.Ack（确认当前消息）、 Basic.Nack（否定当前消息） 、 Basic.Reject（拒绝当前消息） 后，RabbitMQ 收到这些消息后，才认为本次投递完成。

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 2.3	RabbitMQ 事务消息原理是什么

##### 发送方事务

开启事务，发送多条数据，事务提交或回滚是原子的，要么都提交，要么都回滚

<br>

##### 消费方事务

rabbitmq 的消费行为会触发 queue 中 msg 的是否删除、是否重新放回队列等行为。所以，消费方的 ack 必须手动提交的，且最终确定以事务的提交和回滚决定。

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 2.4	RabbitMQ死信队列、延时队列分别是什么

##### 什么是死信

队列中的消息被拒绝、或过期后就成为了死信。

<br>

##### 死信队列

死信可以被重新发布到另一个交换器，这个交换器就是 DLX（Dead Letter Exchange，死信交换器），与 DLX 绑定的队列称为死信队列。

<br>

##### 造成死信的原因

1. 信息被拒绝
2. 信息超时
3. 超过了队列的最大长度

<br>

##### 过期消息

在 rabbitmq 中可以通过两种方式设置消息的过期时间：

1. **队列设置**：在队列申明的时候使用 x-message-ttl 参数（单位毫秒）设置过期时间。设置后，该队列中所有的消息都存在相同的过期时间。
2. **单个消息设置**：设置消息属性的 expiration 参数（单位毫秒）的值，每条消息的过期时间都是独立的。

<br>

##### 延迟队列

延迟队列存储的是延迟消息。

###### 什么是延迟消息

延迟消息指的是，当消息被发发布出去之后，并不立即投递给消费者，而是在指定时间之后投递。

###### rabbitMq 中的延迟队列实现

**rabbitMq 没有直接支持延迟队列，可以通过死信队列实现**。

在死信队列中，可以为普通交换器绑定多个消息队列，假设绑定过期时间为5分钟，10分钟和30分钟，3个消息队列，然后为每个消息队列设置DLX，为每个DLX关联一个死信队列。

当消息过期之后，被转存到对应的死信队列中，然后投递给指定的消费者消费。

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

# 3	kafka 

## 3.1	kafka 的架构设计

##### 核心概念

###### broker

Kafka 集群包含一个或多个服务器，服务器节点称为 broker：

1. broker存储 topic 的数据。如果某 topic 有 N 个 partition，集群有 N 个 broker，那么每个 broker 存储该 topic 的一个 partition。
2. 如果某 topic 有 N 个 partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。
3. 如果某 topic 有 N 个 partition，集群中 broker 数目少于N个，那么一个 broker 存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

###### Topic

每条发布到Kafka集群的消息都有一个类别，这个类别被称为 Topic（类似于数据库的表名）。物理上不同 Topic 的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

######  Partition

topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。

###### Leader

每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。

###### Follower

Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。

###### Producer

生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。

###### Consumer

消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。

###### Consumer Group

每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制-给consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。

###### Offset

kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka

<br>

##### KAFKA 简介

KAFKA 天生是分布式的，满足 AKF 的 XYZ 轴特点，扩展性，可靠性，高性能是没得说。而且，kafka具备自己的特色，比如动态ISR集合，是在强一致性，过半一致性之外的另一个实现手。

kafka 是由 producer 决定 msg 发送到那个queue

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 3.2	Kafka 消息丢失的场景有哪些

##### Kafka 消息丢失的三种场景

1. 生产者在生产过程中的消息丢失
2. broker 在故障后的消息丢失
3. 消费者在消费过程中的消息丢失

<br>

##### ACK机制

ack有3个可选值，分别是1，0，-1：

1. ack=0：生产者在生产过程中的消息丢失，简单来说就是，producer发送一次就不再发送了，不管是否发送成功。

2. ack=1：broker在故障后的消息丢失，简单来说就是，producer只要收到一个分区副本成功写入的通知就认为推送消息成功了。这里有一个地方需要注意，这个副本必须是leader副本。只有leader副本成功写入了，producer才会认为消息发送成功。

   注意，ack的默认值就是1。这个默认值其实就是吞吐量与可靠性的一个折中方案。生产上我们可以根据实际情况进行调整，比如如果你要追求高吞吐量，那么就要放弃可靠性。

3. ack=-1：生产侧和存储侧不会丢失数据，简单来说就是，producer只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。

<br>

##### Offset机制

kafka消费者的三种消费语义：

1. at-most-once：最多一次，可能丢数据
2. at-least-once：最少一次，可能重复消费数据
3. exact-once message：精确一次

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 3.3	kafka customer 的消息获取方式



Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。

Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。

一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。

这样做有好处也有坏处：由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。

消息系统都致力于让consumer以最大的速率最快速的消费消息，但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。

最终Kafka还是选取了传统的pull模式。

Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。

Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。

如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。

Pull模式下，consumer就可以根据自己的消费能力去决定这些策略。

Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。

为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 3.4	Kafka中zk的作用是什么

Zookeeper是分布式协调，注意它不是数据库

kafka中使用了zookeeper的分布式锁和分布式配置及统一命名的分布式协调解决方案

在kafka的broker集群中的controller的选择，是通过zk的临时节点争抢获得的

brokerID等如果自增的话也是通过zk的节点version实现的全局唯一

kafka中broker中的状态数据也是存储在zk中，不过这里要注意，zk不是数据库，所以存储的属于元数据

而，新旧版本变化中，就把曾经的offset从zk中迁移出了zk

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 3.5	Kafka中高性能如何保障

首先，性能的最大瓶颈依然是IO，这个是不能逾越的鸿沟

虽然，broker在持久化数据的时候已经最大努力的使用了磁盘的顺序读写

更进一步的性能优化是零拷贝的使用，也就是从磁盘日志到消费者客户端的数据传递，因为kafka是mq，对于msg不具备加工处理，所以得以实现

然后就是大多数分布式系统一样，总要做tradeoff，在速度与可用性/可靠性中挣扎

ACK的0，1，-1级别就是在性能和可靠中权衡

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

## 3.6	kafka的rebalance机制是什么

##### 消费者分区分配策略

Range 范围分区(默认的)

RoundRobin 轮询分区

Sticky策略

<br>

##### 触发 Rebalance 的时机

Rebalance 的触发条件有3个。

- 组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。
- 订阅的 Topic 个数发生变化。
- 订阅 Topic 的分区数发生变化。

<br>

##### Coordinator协调过程

消费者如何发现协调者

消费者如何确定分配策略

如果需要再均衡分配策略的影响

<br>

---

<div STYLE="page-break-after: always;"><br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br></div>

# 附录

##### 参考资料

- 主要参考资料——[2022年最新【Java经典面试题300问】面试必备，查漏补缺；多线程+spring+JVM调优+分布式+redis+算法](https://www.bilibili.com/video/BV15v4y1T7fz?p=80&spm_id_from=pageDriver&vd_source=87ed5edcdc8042ca0c34ee5bbeeda7b3) 发布于 2022/06/29
- [1.1	消息中间件简介](#1.1	消息中间件简介)——[什么是消息中间件](https://juejin.cn/post/6952509198722662407) 发布于 2021/04/18；
- [1.2	消息队列的底层实现方式](#1.2	消息队列的底层实现方式)——[什么是消息中间件](https://juejin.cn/post/6952509198722662407) 发布于 2021/04/18；
- [1.3	四种常用的消息中间件](#1.3	四种常用的消息中间件)——[四种常用消息中间件比较分析(RabbitMQ、ActiveMQ、Kafka、RocketMQ)](https://www.cnblogs.com/JonaLin/p/12673779.html) 发布于 2020/04/10；

<br>

